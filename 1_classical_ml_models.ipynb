{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from lib.dataset import download_tfds_imdb_as_text, download_tfds_imdb_as_text_tiny\n",
    "from lib.classical_ml import run_pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset  = download_tfds_imdb_as_text()\n",
    "tiny_dataset = download_tfds_imdb_as_text_tiny()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple SpaCy tokenizer\n",
      "Best parameters set found on development set:  {'model__C': 0.1}\n",
      "Best F1 on development set: 0.89 2\n",
      "F1 on test set: 0.89\n",
      "Simple SpaCy tokenizer and ignore stop\n",
      "Best parameters set found on development set:  {'model__C': 0.1}\n",
      "Best F1 on development set: 0.88 2\n",
      "F1 on test set: 0.87\n",
      "Simple SpaCy tokenizer, lowercase, lemma\n",
      "Best parameters set found on development set:  {'model__C': 0.1}\n",
      "Best F1 on development set: 0.89 2\n",
      "F1 on test set: 0.88\n"
     ]
    }
   ],
   "source": [
    "# approximate running time: 42 mins\n",
    "    \n",
    "print(\"Simple SpaCy tokenizer\")\n",
    "_, _ = run_pipeline(dataset)\n",
    "\n",
    "print(\"Simple SpaCy tokenizer and ignore stop\")\n",
    "_, _ = run_pipeline(dataset, lower=True, ignore=[\"like_num\", \"is_stop\"])\n",
    "\n",
    "print(\"Simple SpaCy tokenizer, lowercase, lemma\")\n",
    "_, _ = run_pipeline(dataset, lower=True, lemma=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Simple SpaCy tokenizer\n",
    "Best parameters set found on development set:  {'model__C': 0.1}\n",
    "Best F1 on development set: 0.89 2\n",
    "F1 on test set: 0.89\n",
    "Simple SpaCy tokenizer and ignore stop\n",
    "Best parameters set found on development set:  {'model__C': 0.1}\n",
    "Best F1 on development set: 0.88 2\n",
    "F1 on test set: 0.87\n",
    "Simple SpaCy tokenizer, lowercase, lemma\n",
    "Best parameters set found on development set:  {'model__C': 0.1}\n",
    "Best F1 on development set: 0.89 2\n",
    "F1 on test set: 0.88\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2 Vectorizer\n",
    "\n",
    "Prerequisite: If you are not familiar with TFIDF, read see [this](https://nlp.stanford.edu/IR-book/pdf/06vect.pdf).\n",
    "\n",
    "In this experiement, we will try different vectorization techniques; Bigrams, TFIDF and Binary. Although all of them are based one hot encoding, they capture slightly different information from text. \n",
    "\n",
    "- Bigrams:\n",
    "\n",
    "- TFIDF: TFIDF is very common technique for Information Retrieval (IR) and has been long proved that it improves the IR performance. However, text classification and IR are two different problem sets, so this is not neccessary the case. For text classification, we can expect that whatever classification models we use can capture the same things as TFIDF, which is how importance words are, or how much information words contain.\n",
    "\n",
    "- Binary:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple SpaCy tokenizer\n",
      "Best parameters set found on development set:  {'model__C': 0.1}\n",
      "Best F1 on development set: 0.90 2\n",
      "F1 on test set: 0.90\n",
      "Simple SpaCy tokenizer and ignore stop\n",
      "Best parameters set found on development set:  {'model__C': 10}\n",
      "Best F1 on development set: 0.89 2\n",
      "F1 on test set: 0.88\n",
      "Simple SpaCy tokenizer, lowercase, lemma\n",
      "Best parameters set found on development set:  {'model__C': 0.1}\n",
      "Best F1 on development set: 0.89 2\n",
      "F1 on test set: 0.88\n"
     ]
    }
   ],
   "source": [
    "# approximate running time: 82 mins\n",
    "    \n",
    "print(\"Simple SpaCy tokenizer\")\n",
    "_, _ = run_pipeline(dataset, lower=True, lemma=True, bigram=True)\n",
    "\n",
    "print(\"Simple SpaCy tokenizer and ignore stop\")\n",
    "_, _ = run_pipeline(dataset, lower=True, lemma=True, tfidf=True)\n",
    "\n",
    "print(\"Simple SpaCy tokenizer, lowercase, lemma\")\n",
    "_, _ = run_pipeline(dataset, lower=True, lemma=True, binary=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Simple SpaCy tokenizer\n",
    "Best parameters set found on development set:  {'model__C': 0.1}\n",
    "Best F1 on development set: 0.90 2\n",
    "F1 on test set: 0.90\n",
    "Simple SpaCy tokenizer and ignore stop\n",
    "Best parameters set found on development set:  {'model__C': 10}\n",
    "Best F1 on development set: 0.89 2\n",
    "F1 on test set: 0.88\n",
    "Simple SpaCy tokenizer, lowercase, lemma\n",
    "Best parameters set found on development set:  {'model__C': 0.1}\n",
    "Best F1 on development set: 0.89 2\n",
    "F1 on test set: 0.88\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3 Model\n",
    "\n",
    "- Naive Bayes\n",
    "- Logisitc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple NB\n",
      "Best parameters set found on development set:  {}\n",
      "Best F1 on development set: 0.84 2\n",
      "F1 on test set: 0.80\n",
      "167.90781021118164\n"
     ]
    }
   ],
   "source": [
    "# approximate running time: 3 mins\n",
    "\n",
    "import time\n",
    "now = time.time()\n",
    "print(\"Simple NB\")\n",
    "_, _ = run_pipeline(dataset, use_nb=True)\n",
    "    \n",
    "    \n",
    "print(time.time()-now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Simple SpaCy tokenizer, lowercase, lemma\n",
    "Load tokenized document from disk\n",
    "Load tokenized document from disk\n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) {}\n",
    "Best parameters set found on development set:  {}\n",
    "Best F1 on development set: 0.84\n",
    "F1 on test set: 0.80\n",
    "164.55402326583862\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
