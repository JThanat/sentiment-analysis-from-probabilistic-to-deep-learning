{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "Study\n",
    "- model token effect\n",
    "- polling technique effect\n",
    "- model changes\n",
    "    - GloVe\n",
    "    - Word2Vec\n",
    "    - train on train data \n",
    "    - transfer learning\n",
    "- for train on train data\n",
    "    - effect of span\n",
    "    - effect of dim\n",
    "    - effect of epoch (can it overfit?)\n",
    "\n",
    "- deal with unknwon\n",
    " - zero\n",
    " - random\n",
    " - average\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from dataset import download_tfds_imdb_as_text, download_tfds_imdb_as_text_tiny\n",
    "from word_emb import run_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_models = {\n",
    "    \"word2vec\": gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True),\n",
    "    \"glove\": gensim.models.KeyedVectors.load_word2vec_format('./glove.840B.300d.w2vformat.txt', binary=False) \n",
    "}\n",
    "\n",
    "dataset  = download_tfds_imdb_as_text()\n",
    "tiny_dataset = download_tfds_imdb_as_text_tiny()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 - Effect text preprocess\n",
    "\n",
    "- lower / not lower\n",
    "- remove stop/ punct /number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple SpaCy tokenizer\n",
      "Load tokenized document from disk\n",
      "Load tokenized document from disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:  {'C': 10}\n",
      "Best F1 on development set: 0.69\n",
      "F1 on test set: 0.67\n",
      "Simple SpaCy tokenizer and lowercase\n",
      "Load tokenized document from disk\n",
      "Load tokenized document from disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:  {'C': 1000}\n",
      "Best F1 on development set: 0.72\n",
      "F1 on test set: 0.71\n",
      "Simple SpaCy tokenizer, lowercase, ignore stop words and numbers\n",
      "Load tokenized document from disk\n",
      "Load tokenized document from disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:  {'C': 100}\n",
      "Best F1 on development set: 0.73\n",
      "F1 on test set: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/pmeemeng/miniconda/envs/procore-data/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "def exp1(dataset):\n",
    "    \n",
    "    print(\"Simple SpaCy tokenizer\")\n",
    "    _, _ = run_pipeline(dataset, word_emb_models[\"word2vec\"])\n",
    "\n",
    "    print(\"Simple SpaCy tokenizer and lowercase\")\n",
    "    _, _ = run_pipeline(dataset, word_emb_models[\"word2vec\"], lower=True)\n",
    "    \n",
    "    print(\"Simple SpaCy tokenizer, lowercase, ignore stop words and numbers\")\n",
    "    _, _ = run_pipeline(dataset, word_emb_models[\"word2vec\"], lower=True, ignore=[\"like_num\", \"is_stop\"])\n",
    "\n",
    "# approximate running time: 16 mins\n",
    "exp1(dataset)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 1 Discussion**\n",
    "```\n",
    "Simple SpaCy tokenizer\n",
    "Load tokenized document from disk\n",
    "Load tokenized document from disk\n",
    "Best parameters set found on development set:  {'C': 10}\n",
    "Best F1 on development set: 0.85\n",
    "F1 on test set: 0.85\n",
    "Simple SpaCy tokenizer and lowercase\n",
    "Load tokenized document from disk\n",
    "Load tokenized document from disk\n",
    "Best parameters set found on development set:  {'C': 10}\n",
    "Best F1 on development set: 0.85\n",
    "F1 on test set: 0.85\n",
    "Simple SpaCy tokenizer, lowercase, ignore stop words and numbers\n",
    "Load tokenized document from disk\n",
    "Load tokenized document from disk\n",
    "Best parameters set found on development set:  {'C': 10}\n",
    "Best F1 on development set: 0.84\n",
    "F1 on test set: 0.84\n",
    "954.2723577022552\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2 - Effect of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec\n",
      "Load tokenized document from disk\n",
      "Load tokenized document from disk\n",
      "Best parameters set found on development set:  {'C': 10}\n",
      "Best F1 on development set: 0.85\n",
      "F1 on test set: 0.85\n",
      "GloVe\n",
      "Load tokenized document from disk\n",
      "Load tokenized document from disk\n",
      "Best parameters set found on development set:  {'C': 1000}\n",
      "Best F1 on development set: 0.86\n",
      "F1 on test set: 0.85\n",
      "742.7005350589752\n"
     ]
    }
   ],
   "source": [
    "def exp2(dataset):\n",
    "    print(\"Word2Vec\")\n",
    "    _, _ = run_pipeline(dataset, word_emb_models[\"word2vec\"])\n",
    "\n",
    "    print(\"GloVe\")\n",
    "    _, _ = run_pipeline(dataset, word_emb_models[\"glove\"])\n",
    "    \n",
    "\n",
    "# approximate running time: 13 mins\n",
    "import time\n",
    "now = time.time()\n",
    "exp2(dataset)\n",
    "print(time.time()-now)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 2 Discussion**\n",
    "\n",
    "\n",
    "```\n",
    "Word2Vec\n",
    "Load tokenized document from disk\n",
    "Load tokenized document from disk\n",
    "Best parameters set found on development set:  {'C': 10}\n",
    "Best F1 on development set: 0.85\n",
    "F1 on test set: 0.85\n",
    "GloVe\n",
    "Load tokenized document from disk\n",
    "Load tokenized document from disk\n",
    "Best parameters set found on development set:  {'C': 1000}\n",
    "Best F1 on development set: 0.86\n",
    "F1 on test set: 0.85\n",
    "742.7005350589752\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3 - of tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm\n",
      "Load tokenized document from disk\n"
     ]
    }
   ],
   "source": [
    "def exp3(dataset):\n",
    "    print(\"norm\")\n",
    "    _, _ = run_pipeline(dataset, word_emb_models[\"word2vec\"])\n",
    "    \n",
    "    print(\"norm + idf\")\n",
    "    _, _ = run_pipeline(dataset, word_emb_models[\"word2vec\"], tfidf=True)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# approximate running time:  mins\n",
    "import time\n",
    "now = time.time()\n",
    "exp3(dataset)\n",
    "print(time.time()-now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4 - of polling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp4(dataset):\n",
    "    print(\"norm\")\n",
    "    _, _ = run_pipeline(dataset, word_emb_models[\"word2vec\"], tfidf=True, polling=\"norm\")\n",
    "    \n",
    "    print(\"sum\")\n",
    "    _, _ = run_pipeline(dataset, word_emb_models[\"word2vec\"], tfidf=True, polling=\"sum\")\n",
    "    \n",
    "    print(\"log\")\n",
    "    _, _ = run_pipeline(dataset, word_emb_models[\"word2vec\"], tfidf=True, polling=\"log\")\n",
    "    \n",
    "# approximate running time:  mins\n",
    "import time\n",
    "now = time.time()\n",
    "exp4(dataset)\n",
    "print(time.time()-now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Exp1-4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 5 - Train new wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 6 - Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
