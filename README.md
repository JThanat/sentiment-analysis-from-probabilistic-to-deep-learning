# Text Classification: From Probabilistic Models To Deep Learning

## Introduction

TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO


**Why text classification problem set is so important?**

I intentionally used word "Text Classification" not "Sentiment Analysis" for reasons. 
While the dataset we use here is for sentiment analysis, we can apply the same concepts
to the broader problem set - text classification. We can think of sentiment analysis 
as a subset of text classification, where classes are good and bad sentiment.

Generally, the real word problems are not neccesary well-scoped, as they are created
from human perspective not acadamic. What we usually do is to reduce those problems into
some problem sets that are well-scoped that we know how to solve. Fortunately, lots of 
NLP problems in real world can be reduced to text classification. The very basic examples
that are shown up in almost every NLP / ML textbook include
- sentiment analysis e.g. movie reviews, food reviews, product reviews
- spam detection

However, there are a lot more. For example
- Query Classification - While this is by no means the only way to solve this problem,
text classification ...
- Text Scoring - 
- Data Enrichment - Imagine

**A bit about dataset**

TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO


**Do and Don't**

DOs
- empiricial study

DONTs
- novel techniques

**Prerequisite**

- If you have background in ML but not NLP, you may follow each experiment one by one
and follow the link to optional readings. At the end, you will learn fundamental concept
of text classifcation problems are related NLP area.
- If you have background in ML and NLP, you may jump into specfic notebooks or experiements
that you are interested in particular.
    
**Environmental Setup**

    - Python 3.6, venv, requirements.txt, SpaCy
    - Models (for unning Notebook 2,3)
    - Models BERT (
    
**Sections**

TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO

## 1. Classical Machine Learning Models

TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO

## 2. Word Embeddings

TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO


## 3. More on Word Embeddings

TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO

## 4. BERT

TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO

## 5. GPT-2

TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO
TODO TODO TODO TODO TODO TODO TODO TODO